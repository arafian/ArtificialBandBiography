# -*- coding: utf-8 -*-
"""WikiParser.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f6i-l5fDdR-PpsA-2FLRNnsQGN5ChxPV
"""

import requests
import urllib.request
import time
from bs4 import BeautifulSoup
import re
from urllib.request import urlopen
import json
import pandas
from parse_infobox import parse_infobox
from paragraph_placeholders import get_paragraph_placeholders
from parse_albums import parse_albums

def extractRawData(soup):
  """Inserts text into overall dictionary skeleton"""

  bandData["Name"] = soup.title.string[:-12] # get band name


  mydiv = soup.find("div", {"class": "mw-parser-output"})
  children = mydiv.findChildren()

  rawData = []
  numParagraphs = 3 # We only care about the first 2-3 paragraphs
  for c in children:
    if c.name == 'p':
      if numParagraphs > 0:
        if (c.getText() != "\n"):
          rawData.append(re.sub("[\[].*?[\]]", "", c.getText()))
          numParagraphs-=1
  bandData["rawData"] = rawData

def createJSONData(url):
  """Create JSON object representing wikipedia article"""
  html = urlopen(url)
  soup = BeautifulSoup(html, 'html.parser')

  extractRawData(soup)
  bandData["infobox"] = parse_infobox(soup)
  bandData["albums"] = parse_albums(soup)
#   bandData["prunedData"] = get_paragraph_placeholders(bandData)

def appendToConsolidatedData():
   for key in bandData:
      if key == "rawData" or key == "prunedData":
         for i in range(len(bandData[key])):
            allKey = "all"+"RawPara_" + str(i) if key == "rawData" else "all"+"PrunedPara_" + str(i)
            if allKey in consolidatedData:
               currData = consolidatedData[allKey]
               currData.append(bandData[key][i])
            else:
               consolidatedData[allKey] = [bandData[key][i]]


      elif key == "infobox":
        allKey = "allGenres"
        if "Genres" in bandData[key]:
          if allKey in consolidatedData:
            currData = consolidatedData[allKey]
            currData.extend(bandData[key]["Genres"])
          else:
            consolidatedData[allKey] = [bandData[key]["Genres"]]

      else:
        allKey = "all"+key
        if allKey in consolidatedData:
          currData = consolidatedData[allKey]
          currData.append(bandData[key])
        else:
          consolidatedData[allKey] = [bandData[key]]

##########################################################################

colnames = ['url']
data = pandas.read_csv('list_of_bands.csv', names=colnames)
urls = data.url.tolist()

consolidatedData = {}

fileNum = 0
for url in urls:
  print(url)
  bandData = {}
  createJSONData(url)
  appendToConsolidatedData()
  with open('./data/'+str(fileNum)+'.json', 'w', encoding="utf-8") as outfile:
     json.dump(bandData, outfile, indent = 3,
               ensure_ascii = False)

  fileNum = fileNum + 1

with open('./data/consolidatedData.json', 'w', encoding="utf-8") as outfile:
   json.dump(consolidatedData, outfile, indent = 3,
            ensure_ascii = False)
